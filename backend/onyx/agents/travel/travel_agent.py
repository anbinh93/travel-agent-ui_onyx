from __future__ import annotations

from functools import lru_cache
import os
from pathlib import Path
from typing import Any, Dict, List, TypedDict, Optional

from dotenv import load_dotenv
from langgraph.graph import END, StateGraph

try:  # pragma: no cover - import guard exercised via tests
    import google.generativeai as genai  # type: ignore[import-not-found]
except ImportError as _import_exc_gemini:  # pragma: no cover - allowed fallback
    genai = None  # type: ignore[assignment]
    _GEMINI_IMPORT_ERROR = _import_exc_gemini
else:
    _GEMINI_IMPORT_ERROR = None

try:  # pragma: no cover - import guard exercised via tests
    from tavily import TavilyClient  # type: ignore[import-not-found]
except ImportError as _import_exc:  # pragma: no cover - allowed fallback
    TavilyClient = None  # type: ignore[assignment]
    _TAVILY_IMPORT_ERROR = _import_exc
else:
    _TAVILY_IMPORT_ERROR = None

from onyx.agents.base import AgentDefinition
from onyx.agents.registry import register_agent


class TravelState(TypedDict, total=False):
    query: str
    conversation_history: List[Dict[str, str]]
    user_preferences: Dict[str, Any]
    needs_clarification: bool
    clarification_questions: List[str]
    search_results: List[Dict[str, Any]]
    travel_plans: List[Dict[str, Any]]
    answer: str


_ENV_LOADED = False


def _ensure_env_loaded() -> None:
    global _ENV_LOADED
    if _ENV_LOADED:
        return

    candidate_paths: list[Path] = []

    override_path = os.environ.get("ONYX_ENV_FILE")
    if override_path:
        candidate_paths.append(Path(override_path))

    current_path = Path(__file__).resolve()
    parents = list(current_path.parents)
    # Typical structure: [..., travel, agents, onyx, onyx, backend, onyx, ...]
    for depth in (4, 5, 6):
        if depth < len(parents):
            candidate_paths.append(parents[depth] / ".env")

    candidate_paths.append(Path.cwd() / ".env")

    seen: set[Path] = set()
    for path in candidate_paths:
        try:
            path = path.resolve()
        except FileNotFoundError:
            continue
        if path in seen or not path.exists():
            continue
        load_dotenv(path, override=False)
        seen.add(path)

    # Finally load from environment / defaults in case nothing matched
    load_dotenv(override=False)

    _ENV_LOADED = True


def _validate_required_env() -> None:
    if not os.environ.get("TAVILY_API_KEY") and os.environ.get("TAVILY_APU_KEY"):
        os.environ["TAVILY_API_KEY"] = os.environ["TAVILY_APU_KEY"]

    missing: list[str] = []
    if not os.environ.get("TAVILY_API_KEY"):
        missing.append("TAVILY_API_KEY")
    if not (os.environ.get("GEMINI_API_KEY") or os.environ.get("GEN_AI_API_KEY")):
        missing.append("GEMINI_API_KEY or GEN_AI_API_KEY")
    if missing:
        missing_list = ", ".join(missing)
        raise RuntimeError(
            "Missing environment variables for travel agent: " f"{missing_list}. "
            "Populate them in your Onyx .env file."
        )


def _analyze_user_query(state: TravelState) -> TravelState:
    """Ph√¢n t√≠ch c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng v√† x√°c ƒë·ªãnh xem c√≥ c·∫ßn l√†m r√µ th√™m kh√¥ng"""
    query = state["query"]
    gemini = _gemini_model()
    
    analysis_prompt = f"""
    B·∫°n l√† m·ªôt chuy√™n gia t∆∞ v·∫•n du l·ªãch. Ph√¢n t√≠ch c√¢u h·ªèi c·ªßa kh√°ch h√†ng v√† x√°c ƒë·ªãnh:
    1. C√°c th√¥ng tin ƒë√£ c√≥ (ƒëi·ªÉm ƒë·∫øn, th·ªùi gian, ng√¢n s√°ch, s·ªü th√≠ch...)
    2. C√°c th√¥ng tin c√≤n thi·∫øu c·∫ßn h·ªèi th√™m
    
    C√¢u h·ªèi: {query}
    
    Tr·∫£ v·ªÅ JSON format:
    {{
        "has_destination": true/false,
        "has_duration": true/false,
        "has_budget": true/false,
        "has_interests": true/false,
        "needs_clarification": true/false,
        "clarification_questions": ["c√¢u h·ªèi 1", "c√¢u h·ªèi 2", ...],
        "extracted_preferences": {{
            "destination": "...",
            "duration": "...",
            "budget": "...",
            "interests": ["..."]
        }}
    }}
    """
    
    response = gemini.generate_content(analysis_prompt)
    analysis_text = getattr(response, "text", str(response))
    
    # Parse JSON response (simplified - should use proper JSON parsing)
    import json
    import re
    json_match = re.search(r'\{.*\}', analysis_text, re.DOTALL)
    if json_match:
        try:
            analysis = json.loads(json_match.group())
            state["needs_clarification"] = analysis.get("needs_clarification", False)
            state["clarification_questions"] = analysis.get("clarification_questions", [])
            state["user_preferences"] = analysis.get("extracted_preferences", {})
        except json.JSONDecodeError:
            state["needs_clarification"] = False
    
    return state


def _deep_web_search(state: TravelState) -> TravelState:
    """T√¨m ki·∫øm th√¥ng tin chi ti·∫øt v·ªÅ ƒëi·ªÉm ƒë·∫øn"""
    preferences = state.get("user_preferences", {})
    destination = preferences.get("destination", "")
    interests = preferences.get("interests", [])
    
    # Build comprehensive search query
    search_query = state["query"]
    if destination:
        search_query = f"{destination} travel guide"
        if interests:
            search_query += f" {' '.join(interests)}"
    
    if TavilyClient is None:
        raise RuntimeError("tavily package is required to run the travel agent") from _TAVILY_IMPORT_ERROR
    
    client = TavilyClient()
    
    # Search for multiple aspects
    search_queries = [
        f"{destination} best attractions and places to visit",
        f"{destination} accommodation recommendations",
        f"{destination} local food and restaurants",
        f"{destination} travel tips and transportation"
    ]
    
    all_results = []
    for query in search_queries[:2]:  # Limit to avoid too many API calls
        try:
            results = client.search(
                query=query,
                search_depth="advanced",
                include_answer=True,
                max_results=4,
            )
            all_results.extend(results.get("results", []))
        except Exception:
            continue
    
    state["search_results"] = all_results
    return state


@lru_cache(maxsize=1)
def _gemini_model() -> Any:
    if genai is None:
        raise RuntimeError(
            "google-generativeai package is required to run the travel agent"
        ) from _GEMINI_IMPORT_ERROR

    api_key = os.environ.get("GEMINI_API_KEY") or os.environ.get("GEN_AI_API_KEY")
    if not api_key:
        raise RuntimeError(
            "Missing environment variables for travel agent: GEMINI_API_KEY or GEN_AI_API_KEY."
        )

    genai.configure(api_key=api_key)
    model_name = (
        os.environ.get("GEN_AI_MODEL_VERSION")
        or os.environ.get("GEMINI_MODEL_NAME")
        or "gemini-2.0-flash"
    )
    return genai.GenerativeModel(model_name)


def _create_travel_plans(state: TravelState) -> TravelState:
    """T·∫°o c√°c k·∫ø ho·∫°ch du l·ªãch c√° nh√¢n h√≥a d·ª±a tr√™n preferences v√† search results"""
    preferences = state.get("user_preferences", {})
    documents = state.get("search_results", [])
    
    gemini = _gemini_model()
    
    # Prepare context from search results
    sources_summary = []
    for item in documents:
        title = item.get("title") or ""
        url = item.get("url") or ""
        content = item.get("content") or item.get("snippet") or ""
        sources_summary.append(f"- {title}\n  URL: {url}\n  Info: {content[:300]}")
    
    destination = preferences.get("destination", "ƒëi·ªÉm ƒë·∫øn")
    duration = preferences.get("duration", "v√†i ng√†y")
    budget = preferences.get("budget", "linh ho·∫°t")
    interests = preferences.get("interests", [])
    
    planning_prompt = f"""
    B·∫°n l√† m·ªôt chuy√™n gia t∆∞ v·∫•n du l·ªãch chuy√™n nghi·ªáp. H√£y t·∫°o 3 k·∫ø ho·∫°ch du l·ªãch chi ti·∫øt v√† c√° nh√¢n h√≥a.
    
    TH√îNG TIN KH√ÅCH H√ÄNG:
    - ƒêi·ªÉm ƒë·∫øn: {destination}
    - Th·ªùi gian: {duration}
    - Ng√¢n s√°ch: {budget}
    - S·ªü th√≠ch: {', '.join(interests) if interests else 'ch∆∞a x√°c ƒë·ªãnh'}
    
    TH√îNG TIN T√åM ƒê∆Ø·ª¢C:
    {chr(10).join(sources_summary[:10])}
    
    Y√äU C·∫¶U:
    T·∫°o 3 PLAN kh√°c nhau (Budget-Friendly, Balanced, Premium) v·ªõi:
    
    1. **T√™n k·∫ø ho·∫°ch** v√† phong c√°ch
    2. **T·ªïng quan**: M√¥ t·∫£ ng·∫Øn g·ªçn v·ªÅ k·∫ø ho·∫°ch
    3. **L·ªãch tr√¨nh chi ti·∫øt theo ng√†y**:
       - S√°ng: Ho·∫°t ƒë·ªông + ƒë·ªãa ƒëi·ªÉm c·ª• th·ªÉ
       - Tr∆∞a: ƒÇn tr∆∞a ƒë√¢u + m√≥n g√¨
       - Chi·ªÅu: Ho·∫°t ƒë·ªông + ƒë·ªãa ƒëi·ªÉm
       - T·ªëi: ƒÇn t·ªëi + gi·∫£i tr√≠
    4. **Kh√°ch s·∫°n ƒë·ªÅ xu·∫•t**: T√™n + v·ªã tr√≠ + gi√° tham kh·∫£o
    5. **Chi ph√≠ ∆∞·ªõc t√≠nh**: Chia nh·ªè (ƒÉn, ·ªü, di chuy·ªÉn, vui ch∆°i)
    6. **Tips quan tr·ªçng**: 3-5 l·ªùi khuy√™n h·ªØu √≠ch
    7. **Links tham kh·∫£o**: Tr√≠ch d·∫´n c√°c URL c√≥ s·∫µn
    
    Format markdown r√µ r√†ng, d·ªÖ ƒë·ªçc. ƒê∆∞a ra c√°c g·ª£i √Ω C·ª§ TH·ªÇ, th·ª±c t·∫ø, c√≥ th·ªÉ th·ª±c hi·ªán ƒë∆∞·ª£c.
    """
    
    response = gemini.generate_content(planning_prompt)
    plans_text = getattr(response, "text", str(response))
    
    state["travel_plans"] = [{
        "content": plans_text,
        "type": "comprehensive_plans"
    }]
    
    return state


def _synthesize_answer(state: TravelState) -> TravelState:
    """T·ªïng h·ª£p c√¢u tr·∫£ l·ªùi cu·ªëi c√πng"""
    if state.get("answer"):
        return state
    
    # N·∫øu c·∫ßn clarification, tr·∫£ v·ªÅ c√¢u h·ªèi
    if state.get("needs_clarification"):
        questions = state.get("clarification_questions", [])
        if questions:
            clarification_text = "ƒê·ªÉ t∆∞ v·∫•n ch√≠nh x√°c h∆°n, cho m√¨nh h·ªèi th√™m:\n\n"
            for i, q in enumerate(questions, 1):
                clarification_text += f"{i}. {q}\n"
            clarification_text += "\nB·∫°n c√≥ th·ªÉ chia s·∫ª th√™m ƒë·ªÉ m√¨nh ƒë∆∞a ra k·∫ø ho·∫°ch ph√π h·ª£p nh·∫•t nh√©! üòä"
            state["answer"] = clarification_text
            return state
    
    # N·∫øu c√≥ travel plans, format output
    travel_plans = state.get("travel_plans", [])
    if travel_plans:
        state["answer"] = travel_plans[0].get("content", "")
    else:
        # Fallback to simple answer
        query = state["query"]
        documents = state.get("search_results", [])
        gemini = _gemini_model()
        
        sources_summary = []
        for item in documents:
            title = item.get("title") or ""
            url = item.get("url") or ""
            content = item.get("content") or item.get("snippet") or ""
            sources_summary.append(f"- {title}\n  {url}\n  {content[:200]}")
        
        prompt = f"""
        D·ª±a tr√™n th√¥ng tin t√¨m ƒë∆∞·ª£c, h√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa kh√°ch h√†ng m·ªôt c√°ch chi ti·∫øt v√† h·ªØu √≠ch.
        
        C√¢u h·ªèi: {query}
        
        Th√¥ng tin:
        {chr(10).join(sources_summary[:5])}
        
        H√£y ƒë∆∞a ra c√¢u tr·∫£ l·ªùi th√¢n thi·ªán, chuy√™n nghi·ªáp v·ªõi c√°c g·ª£i √Ω c·ª• th·ªÉ v√† links tham kh·∫£o.
        """
        
        response = gemini.generate_content(prompt)
        state["answer"] = getattr(response, "text", str(response))
    
    return state


def _should_search(state: TravelState) -> str:
    """Quy·∫øt ƒë·ªãnh c√≥ c·∫ßn search hay ch·ªâ c·∫ßn clarification"""
    if state.get("needs_clarification"):
        return "synthesize"
    return "web_search"


def build_travel_agent_graph() -> Any:
    """X√¢y d·ª±ng workflow graph cho travel agent"""
    graph = StateGraph(TravelState)
    
    # Add nodes
    graph.add_node("analyze", _analyze_user_query)
    graph.add_node("web_search", _deep_web_search)
    graph.add_node("create_plans", _create_travel_plans)
    graph.add_node("synthesize", _synthesize_answer)
    
    # Define flow
    graph.set_entry_point("analyze")
    
    # Conditional routing: n·∫øu c·∫ßn clarification th√¨ skip search
    graph.add_conditional_edges(
        "analyze",
        _should_search,
        {
            "web_search": "web_search",
            "synthesize": "synthesize"
        }
    )
    
    graph.add_edge("web_search", "create_plans")
    graph.add_edge("create_plans", "synthesize")
    graph.add_edge("synthesize", END)
    
    return graph.compile()


@lru_cache(maxsize=1)
def _compiled_graph() -> Any:
    return build_travel_agent_graph()


def run_travel_agent(query: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """
    Travel agent runner compatible with AgentRegistry.
    
    Args:
        query: User's travel query
        context: Additional context (knowledge bases, user info, etc.) - currently unused
    
    Returns:
        Dict with answer, sources, and plans
    """
    normalized_query = query.strip()
    if not normalized_query:
        raise ValueError("Query must be a non-empty string")

    _ensure_env_loaded()
    _validate_required_env()

    compiled = _compiled_graph()
    initial: TravelState = {"query": normalized_query}
    final_state: TravelState = compiled.invoke(initial)
    return {
        "answer": final_state.get("answer", ""),
        "sources": [
            {"title": r.get("title"), "url": r.get("url")}
            for r in final_state.get("search_results", [])
        ],
    }


register_agent(
    AgentDefinition(
        key="travel_planning_agent",
        name="AI Travel Planning Assistant",
        description=(
            "Tr·ª£ l√Ω du l·ªãch th√¥ng minh v·ªõi kh·∫£ nƒÉng:\n"
            "‚Ä¢ ƒê·∫∑t c√¢u h·ªèi ƒë·ªÉ hi·ªÉu r√µ nhu c·∫ßu kh√°ch h√†ng\n"
            "‚Ä¢ T√¨m ki·∫øm th√¥ng tin chi ti·∫øt v·ªÅ ƒëi·ªÉm ƒë·∫øn\n"
            "‚Ä¢ L·∫≠p k·∫ø ho·∫°ch du l·ªãch c√° nh√¢n h√≥a v·ªõi 3 l·ª±a ch·ªçn (Budget/Balanced/Premium)\n"
            "‚Ä¢ ƒê·ªÅ xu·∫•t l·ªãch tr√¨nh chi ti·∫øt theo ng√†y, kh√°ch s·∫°n, ƒÉn u·ªëng, chi ph√≠\n"
            "‚Ä¢ Cung c·∫•p tips v√† links h·ªØu √≠ch"
        ),
        runner=run_travel_agent,
    )
)


